{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mskang/.conda/envs/server/lib/python3.9/site-packages/xgboost/compat.py:93: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import sys\n",
    "import sktime\n",
    "import tqdm as tq\n",
    "import xgboost as xgb\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.utils.plotting import plot_series\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "pd.set_option('display.max_columns', 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU 포트 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device : cuda\n",
      "Current : 0\n",
      "Count : 1\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('device :', device)\n",
    "print('Current :', torch.cuda.current_device())\n",
    "print('Count :', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>date_time</th>\n",
       "      <th>power</th>\n",
       "      <th>prec</th>\n",
       "      <th>wind</th>\n",
       "      <th>hum</th>\n",
       "      <th>temp</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>day_hour_mean</th>\n",
       "      <th>day_hour_std</th>\n",
       "      <th>holiday</th>\n",
       "      <th>sin_time</th>\n",
       "      <th>cos_time</th>\n",
       "      <th>THI</th>\n",
       "      <th>CDH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-01 00:00:00</td>\n",
       "      <td>1085.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>42.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1774.744615</td>\n",
       "      <td>517.982222</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.6576</td>\n",
       "      <td>-5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-01 01:00:00</td>\n",
       "      <td>1047.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>45.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1687.347692</td>\n",
       "      <td>500.769931</td>\n",
       "      <td>1</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>47.7625</td>\n",
       "      <td>-11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-01 02:00:00</td>\n",
       "      <td>974.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>17.7</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1571.483077</td>\n",
       "      <td>465.227458</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>47.2225</td>\n",
       "      <td>-17.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-01 03:00:00</td>\n",
       "      <td>953.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>48.0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1522.153846</td>\n",
       "      <td>436.601091</td>\n",
       "      <td>1</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>44.7856</td>\n",
       "      <td>-25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-01 04:00:00</td>\n",
       "      <td>986.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>43.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1506.793846</td>\n",
       "      <td>405.518091</td>\n",
       "      <td>1</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>49.0061</td>\n",
       "      <td>-30.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num            date_time    power  prec  wind   hum  temp  day  week  \\\n",
       "0    1  2022-06-01 00:00:00  1085.28   0.0   0.9  42.0  18.6    2    22   \n",
       "1    1  2022-06-01 01:00:00  1047.36   0.0   1.1  45.0  18.0    2    22   \n",
       "2    1  2022-06-01 02:00:00   974.88   0.0   1.5  45.0  17.7    2    22   \n",
       "3    1  2022-06-01 03:00:00   953.76   0.0   1.4  48.0  16.7    2    22   \n",
       "4    1  2022-06-01 04:00:00   986.40   0.0   2.8  43.0  18.4    2    22   \n",
       "\n",
       "   day_hour_mean  day_hour_std  holiday  sin_time  cos_time      THI   CDH  \n",
       "0    1774.744615    517.982222        1  0.000000  1.000000  49.6576  -5.4  \n",
       "1    1687.347692    500.769931        1  0.258819  0.965926  47.7625 -11.4  \n",
       "2    1571.483077    465.227458        1  0.500000  0.866025  47.2225 -17.7  \n",
       "3    1522.153846    436.601091        1  0.707107  0.707107  44.7856 -25.0  \n",
       "4    1506.793846    405.518091        1  0.866025  0.500000  49.0061 -30.6  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전처리 한 파일 불러오기\n",
    "train = pd.read_csv('./data/xgboost/train_preprocessed_incsolor.csv', index_col=0)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./data/xgboost/test_preprocessed_incsolor.csv', index_col = 0)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SMAPE loss function\n",
    "def SMAPE(true, pred):\n",
    "    return np.mean((np.abs(true-pred))/(np.abs(true) + np.abs(pred))) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eta(learning rate) : 0.01 로 했을 때보다 0.05로 했을 때 결과가 좋게 나옴  \n",
    "최적의 eta 값을 찾기 위해 바꿔가며 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/home/mskang/.conda/envs/server/lib/python3.9/site-packages/xgboost/data.py:173: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 168 candidates, totalling 1680 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [12:33<20:43:48, 753.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.9, 'eta': 0.07, 'max_depth': 5, 'min_child_weight': 6, 'n_estimators': 100, 'subsample': 0.8}\n",
      "building1|| SMAPE : 1.5148426683419873\n",
      "Fitting 10 folds for each of 168 candidates, totalling 1680 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mskang/.conda/envs/server/lib/python3.9/site-packages/xgboost/data.py:173: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "  2%|▏         | 2/100 [24:48<20:13:07, 742.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.8, 'eta': 0.07, 'max_depth': 7, 'min_child_weight': 2, 'n_estimators': 100, 'subsample': 0.8}\n",
      "building2|| SMAPE : 1.0043933693459162\n",
      "Fitting 10 folds for each of 168 candidates, totalling 1680 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mskang/.conda/envs/server/lib/python3.9/site-packages/xgboost/data.py:173: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "  3%|▎         | 3/100 [37:04<19:55:42, 739.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.9, 'eta': 0.07, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 0.8}\n",
      "building3|| SMAPE : 2.891783319865605\n",
      "Fitting 10 folds for each of 168 candidates, totalling 1680 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mskang/.conda/envs/server/lib/python3.9/site-packages/xgboost/data.py:173: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "  4%|▍         | 4/100 [48:30<19:09:16, 718.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.8, 'eta': 0.07, 'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 100, 'subsample': 0.9}\n",
      "building4|| SMAPE : 1.6763882841392252\n",
      "Fitting 10 folds for each of 168 candidates, totalling 1680 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mskang/.conda/envs/server/lib/python3.9/site-packages/xgboost/data.py:173: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import PredefinedSplit, GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "smape = make_scorer(SMAPE, greater_is_better = False)\n",
    "\n",
    "df = pd.DataFrame(columns = ['n_estimators', 'eta', 'min_child_weight','max_depth', 'colsample_bytree', 'subsample'])\n",
    "# df = pd.read_csv('./data/xgboost/hyperparameter_xgb_solar.csv')\n",
    "preds = np.array([])\n",
    "\n",
    "grid = {'n_estimators' : [100], 'eta' : [0.07], 'min_child_weight' : np.arange(1, 8, 1),\n",
    "        'max_depth' : np.arange(3,9,1) , 'colsample_bytree' :np.arange(0.8, 1.0, 0.1),\n",
    "        'subsample' :np.arange(0.8, 1.0, 0.1)} # fix the eta(learning rate)\n",
    "\n",
    "# 건물 번호별로 GridSearch로 parameter 생성\n",
    "for i in tqdm(np.arange(1, 101)):\n",
    "    y = train.loc[train.num == i, 'power']\n",
    "    x = train.loc[train.num == i, ].iloc[:, 3:]\n",
    "    # 마지막 일주일 발전량을 validset으로 24시간*7일 = 168\n",
    "    y_train, y_test, x_train, x_test = temporal_train_test_split(y = y, X = x, test_size = 168)\n",
    "\n",
    "\n",
    "    # pds = PredefinedSplit(np.append(-np.ones(len(x)-168), np.zeros(168)))\n",
    "    gcv = GridSearchCV(estimator = XGBRegressor(seed = 10, gpu_id = 0,\n",
    "                                                tree_method = 'gpu_hist', predictor= 'gpu_predictor'),\n",
    "                       param_grid = grid, scoring = smape, cv = 10, refit = True, verbose = True)\n",
    "\n",
    "\n",
    "    gcv.fit(x, y)\n",
    "    best = gcv.best_estimator_\n",
    "    params = gcv.best_params_\n",
    "    print(params)\n",
    "    pred = best.predict(x_test)\n",
    "    building = 'building'+str(i)\n",
    "    print(building + '|| SMAPE : {}'.format(SMAPE(y_test, pred)))\n",
    "    preds = np.append(preds, pred)\n",
    "    df = pd.concat([df, pd.DataFrame(params, index = [0])], axis = 0)\n",
    "    df.to_csv('./data/xgboost/hyperparameter_xgb_solar.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = pd.read_csv('./data/xgboost/hyperparameter_xgb_solar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손실함수를 rmse 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weighted_mse 는 모든 파라미터 학습 후에 적용해보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n_estimators 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted_mse 쓰는것과 안쓰는 것 차이 확인\n",
    "# weighted_mse 안쓰는 것이 더 점수 높게 나오네?? 둘다 실험해보자\n",
    "\n",
    "scores = []   # smape 값을 저장할 list\n",
    "best_it = []  # best interation을 저장할 list\n",
    "for i in tqdm(range(100)):\n",
    "    y = train.loc[train.num == i+1, 'power']\n",
    "    x = train.loc[train.num == i+1, ].iloc[:, 3:]\n",
    "    y_train, y_valid, x_train, x_valid = temporal_train_test_split(y = y, X = x, test_size = 168)\n",
    "    \n",
    "    xgb_reg = XGBRegressor(n_estimators = 1000, eta = xgb_params.iloc[i, 1], min_child_weight = xgb_params.iloc[i, 2],\n",
    "                           max_depth = xgb_params.iloc[i, 3], colsample_bytree = xgb_params.iloc[i, 4], \n",
    "                           subsample = xgb_params.iloc[i, 5], seed=10)\n",
    "    # xgb_reg.set_params(**{'objective':weighted_mse(100)}) # alpha = 100으로 고정\n",
    "    \n",
    "    xgb_reg.fit(x_train, y_train, eval_set=[(x_train, y_train), \n",
    "                                            (x_valid, y_valid)], early_stopping_rounds=300, verbose=False)\n",
    "    y_pred = xgb_reg.predict(x_valid)\n",
    "    pred = pd.Series(y_pred)   \n",
    "    \n",
    "    sm = SMAPE(y_valid, y_pred)\n",
    "    scores.append(sm)\n",
    "    best_it.append(xgb_reg.best_iteration) ## 실제 best iteration은 이 값에 +1 해주어야 함.\n",
    "    print(\"building {} || best iter : {} || smape : {}\".format(i+1, xgb_reg.best_iteration, sm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 튜닝한 n_estimators 적용시켜서 smape 값 추출\n",
    "smape_list = []\n",
    "for i in tqdm(range(100)):\n",
    "    y = train.loc[train.num == i+1, 'power']\n",
    "    x = train.loc[train.num == i+1, ].iloc[:, 3:]\n",
    "    y_train, y_test, x_train, x_test = temporal_train_test_split(y = y, X = x, test_size = 168)\n",
    "    xgb = XGBRegressor(seed = 10,\n",
    "                      n_estimators = best_it[i], eta = xgb_params.iloc[i, 1], min_child_weight = xgb_params.iloc[i, 2],\n",
    "                      max_depth = xgb_params.iloc[i, 3], colsample_bytree = xgb_params.iloc[i, 4], subsample = xgb_params.iloc[i, 5], eval_metric = 'rmse')\n",
    "    \n",
    "    xgb.fit(x_train, y_train)\n",
    "    pred0 = xgb.predict(x_test)\n",
    "    score0 = SMAPE(y_test,pred0)\n",
    "\n",
    "    smape_list.append(score0)\n",
    "    print(\"building {} || best score : {}\".format(i+1, score0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_df = pd.DataFrame({'score':smape_list})\n",
    "plt.bar(np.arange(len(no_df))+1, no_df['score'])\n",
    "plt.plot([1,100], [5, 5], color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params['best_it'] = best_it\n",
    "xgb_params.to_csv('./data/xgboost/hyperparameter_xgb_solar_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## best hyperparameters 불러오기\n",
    "xgb_params = pd.read_csv('./data/xgboost/hyperparameter_xgb_solar_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test 전처리 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./data/xgboost/test_preprocessed_incsolor.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array([]) \n",
    "for i in tqdm(range(100)):\n",
    "    \n",
    "    y_train = train.loc[train.num == i+1, 'power']\n",
    "    x_train, x_test = train.loc[train.num == i+1, ].iloc[:, 3:], test.loc[test.num == i+1, ].iloc[:,2:]\n",
    "    x_test = x_test[x_train.columns]\n",
    "    \n",
    "    xgb = XGBRegressor(seed = 10, n_estimators = xgb_params.iloc[i, -1], eta = xgb_params.iloc[i, 1], \n",
    "                        min_child_weight = xgb_params.iloc[i, 2], max_depth = xgb_params.iloc[i, 3], \n",
    "                        colsample_bytree=xgb_params.iloc[i, 4], subsample=xgb_params.iloc[i, 5])\n",
    "\n",
    "    # if xgb_params.iloc[i,6] != 0:  # 만약 alpha가 0이 아니면 weighted_mse 사용\n",
    "    #     xgb.set_params(**{'objective':weighted_mse(xgb_params.iloc[i,6])})\n",
    "    \n",
    "    xgb.fit(x_train, y_train)\n",
    "    y_pred = xgb.predict(x_test)\n",
    "    preds = np.append(preds, y_pred)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 결과 시각화\n",
    "\n",
    "preds = pd.Series(preds)\n",
    "\n",
    "fig, ax = plt.subplots(100, 1, figsize=(100,200), sharex = True)\n",
    "ax = ax.flatten()\n",
    "for i in range(100):\n",
    "    train_y = train.loc[train.num == i+1, 'power'].reset_index(drop = True)\n",
    "    test_y = preds[i*168:(i+1)*168]\n",
    "    ax[i].scatter(np.arange(2040) , train.loc[train.num == i+1, 'power'])\n",
    "    ax[i].scatter(np.arange(2040, 2040+168) , test_y)\n",
    "    ax[i].tick_params(axis='both', which='major', labelsize=6)\n",
    "    ax[i].tick_params(axis='both', which='minor', labelsize=4)\n",
    "#plt.savefig('./predict_xgb.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./data/sample_submission.csv')\n",
    "submission['answer'] = preds\n",
    "submission.to_csv('./data/xgboost/submission_xgb_solor.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손실함수를 임의로 생성한 weighted_mse 사용\n",
    "이 함수를 이용하는 것이 rmse 를 이용하는 것보다 smape 평가지표상에서 더 좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = pd.read_csv('./data/xgboost/hyperparameter_xgb_solar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### alpha를 argument로 받는 함수로 실제 objective function을 wrapping하여 alpha값을 쉽게 조정할 수 있도록 작성했습니다.\n",
    "# custom objective function for forcing model not to underestimate\n",
    "def weighted_mse(alpha = 1):\n",
    "    def weighted_mse_fixed(label, pred):\n",
    "        residual = (label - pred).astype(\"float\")\n",
    "        grad = np.where(residual>0, -2*alpha*residual, -2*residual)\n",
    "        hess = np.where(residual>0, 2*alpha, 2.0)\n",
    "        return grad, hess\n",
    "    return weighted_mse_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []   # smape 값을 저장할 list\n",
    "best_it = []  # best interation을 저장할 list\n",
    "for i in tqdm(range(100)):\n",
    "    y = train.loc[train.num == i+1, 'power']\n",
    "    x = train.loc[train.num == i+1, ].iloc[:, 3:]\n",
    "    y_train, y_valid, x_train, x_valid = temporal_train_test_split(y = y, X = x, test_size = 168)\n",
    "    \n",
    "    xgb_reg = XGBRegressor(n_estimators = 10000, eta = 0.01, min_child_weight = xgb_params.iloc[i, 2],\n",
    "                           max_depth = xgb_params.iloc[i, 3], colsample_bytree = xgb_params.iloc[i, 4], \n",
    "                           subsample = xgb_params.iloc[i, 5], seed=10)\n",
    "    xgb_reg.set_params(**{'objective':weighted_mse(100)}) # alpha = 100으로 고정\n",
    "    \n",
    "    xgb_reg.fit(x_train, y_train, eval_set=[(x_train, y_train), \n",
    "                                            (x_valid, y_valid)], early_stopping_rounds=300, verbose=False)\n",
    "    y_pred = xgb_reg.predict(x_valid)\n",
    "    pred = pd.Series(y_pred)   \n",
    "    \n",
    "    sm = SMAPE(y_valid, y_pred)\n",
    "    scores.append(sm)\n",
    "    best_it.append(xgb_reg.best_iteration) ## 실제 best iteration은 이 값에 +1 해주어야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_list = []\n",
    "smape_list = []\n",
    "for i in tqdm(range(100)):\n",
    "    y = train.loc[train.num == i+1, 'power']\n",
    "    x = train.loc[train.num == i+1, ].iloc[:, 3:]\n",
    "    y_train, y_test, x_train, x_test = temporal_train_test_split(y = y, X = x, test_size = 168)\n",
    "    xgb = XGBRegressor(seed = 10,\n",
    "                      n_estimators = best_it[i], eta = 0.01, min_child_weight = xgb_params.iloc[i, 2],\n",
    "                      max_depth = xgb_params.iloc[i, 3], colsample_bytree = xgb_params.iloc[i, 4], subsample = xgb_params.iloc[i, 5])\n",
    "    \n",
    "    xgb.fit(x_train, y_train)\n",
    "    pred0 = xgb.predict(x_test)\n",
    "    best_alpha = 0\n",
    "    score0 = SMAPE(y_test,pred0)\n",
    "    \n",
    "    for j in range(1, 100, 2):\n",
    "        xgb = XGBRegressor(seed = 10,\n",
    "                      n_estimators = best_it[i], eta = 0.01, min_child_weight = xgb_params.iloc[i, 2],\n",
    "                      max_depth = xgb_params.iloc[i, 3], colsample_bytree = xgb_params.iloc[i, 4], subsample = xgb_params.iloc[i, 5])\n",
    "        xgb.set_params(**{'objective' : weighted_mse(j)})\n",
    "    \n",
    "        xgb.fit(x_train, y_train)\n",
    "        pred1 = xgb.predict(x_test)\n",
    "        score1 = SMAPE(y_test, pred1)\n",
    "        if score1 < score0:\n",
    "            best_alpha = j\n",
    "            score0 = score1\n",
    "    \n",
    "    alpha_list.append(best_alpha)\n",
    "    smape_list.append(score0)\n",
    "    print(\"building {} || best score : {} || alpha : {}\".format(i+1, score0, best_alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params['alpha'] = alpha_list\n",
    "xgb_params['best_it'] = best_it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array([]) \n",
    "for i in tqdm(range(100)):\n",
    "    \n",
    "    y_train = train.loc[train.num == i+1, 'power']\n",
    "    x_train, x_test = train.loc[train.num == i+1, ].iloc[:, 3:], test.loc[test.num == i+1, ].iloc[:,2:]\n",
    "    x_test = x_test[x_train.columns]\n",
    "    \n",
    "    xgb = XGBRegressor(seed = 10, n_estimators = xgb_params.iloc[i, -1], eta = xgb_params.iloc[i, 1], \n",
    "                        min_child_weight = xgb_params.iloc[i, 2], max_depth = xgb_params.iloc[i, 3], \n",
    "                        colsample_bytree=xgb_params.iloc[i, 4], subsample=xgb_params.iloc[i, 5])\n",
    "\n",
    "    if xgb_params.iloc[i,6] != 0:  # 만약 alpha가 0이 아니면 weighted_mse 사용\n",
    "        xgb.set_params(**{'objective':weighted_mse(xgb_params.iloc[i,6])})\n",
    "    \n",
    "    xgb.fit(x_train, y_train)\n",
    "    y_pred = xgb.predict(x_test)\n",
    "    preds = np.append(preds, y_pred)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 결과 시각화\n",
    "\n",
    "preds = pd.Series(preds)\n",
    "\n",
    "fig, ax = plt.subplots(100, 1, figsize=(100,200), sharex = True)\n",
    "ax = ax.flatten()\n",
    "for i in range(100):\n",
    "    train_y = train.loc[train.num == i+1, 'power'].reset_index(drop = True)\n",
    "    test_y = preds[i*168:(i+1)*168]\n",
    "    ax[i].scatter(np.arange(2040) , train.loc[train.num == i+1, 'power'])\n",
    "    ax[i].scatter(np.arange(2040, 2040+168) , test_y)\n",
    "    ax[i].tick_params(axis='both', which='major', labelsize=6)\n",
    "    ax[i].tick_params(axis='both', which='minor', labelsize=4)\n",
    "#plt.savefig('./predict_xgb.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./data/sample_submission.csv')\n",
    "submission['answer'] = preds\n",
    "submission.to_csv('./data/xgboost/submission_xgb_solor_wmse.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "server",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
